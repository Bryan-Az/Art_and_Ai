{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as fun\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hypothesis:\n",
    "A good starting point is to categorize art based on the different continents which latin america lies on. Since the dataset contains 2x the amount of mexican art than ALL OTHER latin american art combined, continent is a good feature to split and train on due to geographical difference and logistic/technical restrictions. Since latin america is only distributed across two continents, it is a good binary target due to lack of data in other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('../data_samples/continents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature = pd.read_csv('../data_samples/results/en_titles.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from TitleDataset import TitleDataset\n",
    "dataset = TitleDataset()\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "random_seed= 42\n",
    "size = len(dataset)\n",
    "indices = list(range(size))\n",
    "split = int(np.floor(validation_split * size))\n",
    "shuffle = True\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices, test_indices = indices[split:], indices[:int(np.floor(split/2))], indices[int(np.floor(split/2)):split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "token_loader = DataLoader(dataset, batch_size=1,\n",
    "                          sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenizer for Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Text Classification Model\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(DEVICE), text_list.to(DEVICE), offsets.to(DEVICE)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                          sampler=train_sampler, collate_fn=collate_batch)\n",
    "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                               sampler=valid_sampler,collate_fn=collate_batch)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                         sampler=valid_sampler, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "263lines [00:00, 7143.01lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "token_iter = token_loader\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(_[0])\n",
    "vocab = build_vocab_from_iterator(yield_tokens(token_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab.__getitem__(tokenizer(y)[0]) for y in x.split(' ')]\n",
    "label_pipeline = lambda x: 0 if x == 'North America' else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 335, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('Mexico Serafina ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from TorchTextModel import TorchTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "vocab_size = len(vocab)\n",
    "emsize=128\n",
    "model = TorchTextModel(vocab_size, emsize, num_class).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import optim\n",
    "EPOCHS = 10\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)\n",
    "total_accu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0,0\n",
    "    log_interval = 1\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(text, offsets)\n",
    "        loss = criterion(prediction, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (prediction.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/   17 batches | accuracy    0.656\n",
      "| epoch   1 |     2/   17 batches | accuracy    0.625\n",
      "| epoch   1 |     3/   17 batches | accuracy    0.875\n",
      "| epoch   1 |     4/   17 batches | accuracy    0.750\n",
      "| epoch   1 |     5/   17 batches | accuracy    0.812\n",
      "| epoch   1 |     6/   17 batches | accuracy    0.562\n",
      "| epoch   1 |     7/   17 batches | accuracy    0.625\n",
      "| epoch   1 |     8/   17 batches | accuracy    0.438\n",
      "| epoch   1 |     9/   17 batches | accuracy    0.562\n",
      "| epoch   1 |    10/   17 batches | accuracy    0.812\n",
      "| epoch   1 |    11/   17 batches | accuracy    0.688\n",
      "| epoch   1 |    12/   17 batches | accuracy    0.688\n",
      "| epoch   1 |    13/   17 batches | accuracy    0.750\n",
      "| epoch   1 |    14/   17 batches | accuracy    0.625\n",
      "| epoch   1 |    15/   17 batches | accuracy    0.688\n",
      "| epoch   1 |    16/   17 batches | accuracy    0.429\n",
      "Current Model ________\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.06s | valid accuracy    0.688 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |     1/   17 batches | accuracy    0.688\n",
      "| epoch   2 |     2/   17 batches | accuracy    0.812\n",
      "| epoch   2 |     3/   17 batches | accuracy    0.562\n",
      "| epoch   2 |     4/   17 batches | accuracy    0.812\n",
      "| epoch   2 |     5/   17 batches | accuracy    0.688\n",
      "| epoch   2 |     6/   17 batches | accuracy    0.688\n",
      "| epoch   2 |     7/   17 batches | accuracy    0.688\n",
      "| epoch   2 |     8/   17 batches | accuracy    0.812\n",
      "| epoch   2 |     9/   17 batches | accuracy    0.625\n",
      "| epoch   2 |    10/   17 batches | accuracy    0.750\n",
      "| epoch   2 |    11/   17 batches | accuracy    0.625\n",
      "| epoch   2 |    12/   17 batches | accuracy    0.750\n",
      "| epoch   2 |    13/   17 batches | accuracy    0.562\n",
      "| epoch   2 |    14/   17 batches | accuracy    0.688\n",
      "| epoch   2 |    15/   17 batches | accuracy    0.688\n",
      "| epoch   2 |    16/   17 batches | accuracy    0.714\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.06s | valid accuracy    0.688 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |     1/   17 batches | accuracy    0.656\n",
      "| epoch   3 |     2/   17 batches | accuracy    0.750\n",
      "| epoch   3 |     3/   17 batches | accuracy    0.938\n",
      "| epoch   3 |     4/   17 batches | accuracy    0.625\n",
      "| epoch   3 |     5/   17 batches | accuracy    0.438\n",
      "| epoch   3 |     6/   17 batches | accuracy    0.750\n",
      "| epoch   3 |     7/   17 batches | accuracy    0.812\n",
      "| epoch   3 |     8/   17 batches | accuracy    0.938\n",
      "| epoch   3 |     9/   17 batches | accuracy    0.688\n",
      "| epoch   3 |    10/   17 batches | accuracy    0.625\n",
      "| epoch   3 |    11/   17 batches | accuracy    0.750\n",
      "| epoch   3 |    12/   17 batches | accuracy    0.938\n",
      "| epoch   3 |    13/   17 batches | accuracy    0.750\n",
      "| epoch   3 |    14/   17 batches | accuracy    0.500\n",
      "| epoch   3 |    15/   17 batches | accuracy    0.812\n",
      "| epoch   3 |    16/   17 batches | accuracy    0.429\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.06s | valid accuracy    0.688 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |     1/   17 batches | accuracy    0.688\n",
      "| epoch   4 |     2/   17 batches | accuracy    0.688\n",
      "| epoch   4 |     3/   17 batches | accuracy    0.812\n",
      "| epoch   4 |     4/   17 batches | accuracy    0.750\n",
      "| epoch   4 |     5/   17 batches | accuracy    0.688\n",
      "| epoch   4 |     6/   17 batches | accuracy    0.812\n",
      "| epoch   4 |     7/   17 batches | accuracy    0.750\n",
      "| epoch   4 |     8/   17 batches | accuracy    0.750\n",
      "| epoch   4 |     9/   17 batches | accuracy    0.812\n",
      "| epoch   4 |    10/   17 batches | accuracy    0.562\n",
      "| epoch   4 |    11/   17 batches | accuracy    0.812\n",
      "| epoch   4 |    12/   17 batches | accuracy    0.625\n",
      "| epoch   4 |    13/   17 batches | accuracy    0.812\n",
      "| epoch   4 |    14/   17 batches | accuracy    0.875\n",
      "| epoch   4 |    15/   17 batches | accuracy    0.562\n",
      "| epoch   4 |    16/   17 batches | accuracy    0.714\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.09s | valid accuracy    0.688 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |     1/   17 batches | accuracy    0.844\n",
      "| epoch   5 |     2/   17 batches | accuracy    0.750\n",
      "| epoch   5 |     3/   17 batches | accuracy    0.812\n",
      "| epoch   5 |     4/   17 batches | accuracy    0.875\n",
      "| epoch   5 |     5/   17 batches | accuracy    0.750\n",
      "| epoch   5 |     6/   17 batches | accuracy    0.562\n",
      "| epoch   5 |     7/   17 batches | accuracy    0.875\n",
      "| epoch   5 |     8/   17 batches | accuracy    0.750\n",
      "| epoch   5 |     9/   17 batches | accuracy    0.750\n",
      "| epoch   5 |    10/   17 batches | accuracy    0.625\n",
      "| epoch   5 |    11/   17 batches | accuracy    0.875\n",
      "| epoch   5 |    12/   17 batches | accuracy    0.625\n",
      "| epoch   5 |    13/   17 batches | accuracy    0.750\n",
      "| epoch   5 |    14/   17 batches | accuracy    0.875\n",
      "| epoch   5 |    15/   17 batches | accuracy    0.625\n",
      "| epoch   5 |    16/   17 batches | accuracy    0.286\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.08s | valid accuracy    0.688 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |     1/   17 batches | accuracy    0.688\n",
      "| epoch   6 |     2/   17 batches | accuracy    0.750\n",
      "| epoch   6 |     3/   17 batches | accuracy    0.562\n",
      "| epoch   6 |     4/   17 batches | accuracy    0.875\n",
      "| epoch   6 |     5/   17 batches | accuracy    0.812\n",
      "| epoch   6 |     6/   17 batches | accuracy    0.688\n",
      "| epoch   6 |     7/   17 batches | accuracy    0.812\n",
      "| epoch   6 |     8/   17 batches | accuracy    0.750\n",
      "| epoch   6 |     9/   17 batches | accuracy    0.688\n",
      "| epoch   6 |    10/   17 batches | accuracy    0.688\n",
      "| epoch   6 |    11/   17 batches | accuracy    0.938\n",
      "| epoch   6 |    12/   17 batches | accuracy    0.812\n",
      "| epoch   6 |    13/   17 batches | accuracy    0.688\n",
      "| epoch   6 |    14/   17 batches | accuracy    0.938\n",
      "| epoch   6 |    15/   17 batches | accuracy    0.688\n",
      "| epoch   6 |    16/   17 batches | accuracy    0.714\n",
      "Current Model ________\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.09s | valid accuracy    0.719 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |     1/   17 batches | accuracy    0.719\n",
      "| epoch   7 |     2/   17 batches | accuracy    0.812\n",
      "| epoch   7 |     3/   17 batches | accuracy    0.750\n",
      "| epoch   7 |     4/   17 batches | accuracy    0.750\n",
      "| epoch   7 |     5/   17 batches | accuracy    0.688\n",
      "| epoch   7 |     6/   17 batches | accuracy    0.875\n",
      "| epoch   7 |     7/   17 batches | accuracy    0.750\n",
      "| epoch   7 |     8/   17 batches | accuracy    0.750\n",
      "| epoch   7 |     9/   17 batches | accuracy    0.625\n",
      "| epoch   7 |    10/   17 batches | accuracy    0.875\n",
      "| epoch   7 |    11/   17 batches | accuracy    0.812\n",
      "| epoch   7 |    12/   17 batches | accuracy    0.750\n",
      "| epoch   7 |    13/   17 batches | accuracy    0.938\n",
      "| epoch   7 |    14/   17 batches | accuracy    0.688\n",
      "| epoch   7 |    15/   17 batches | accuracy    0.812\n",
      "| epoch   7 |    16/   17 batches | accuracy    0.714\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.10s | valid accuracy    0.719 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |     1/   17 batches | accuracy    0.750\n",
      "| epoch   8 |     2/   17 batches | accuracy    0.875\n",
      "| epoch   8 |     3/   17 batches | accuracy    0.750\n",
      "| epoch   8 |     4/   17 batches | accuracy    0.875\n",
      "| epoch   8 |     5/   17 batches | accuracy    0.812\n",
      "| epoch   8 |     6/   17 batches | accuracy    0.750\n",
      "| epoch   8 |     7/   17 batches | accuracy    0.812\n",
      "| epoch   8 |     8/   17 batches | accuracy    0.938\n",
      "| epoch   8 |     9/   17 batches | accuracy    0.812\n",
      "| epoch   8 |    10/   17 batches | accuracy    0.625\n",
      "| epoch   8 |    11/   17 batches | accuracy    0.812\n",
      "| epoch   8 |    12/   17 batches | accuracy    0.750\n",
      "| epoch   8 |    13/   17 batches | accuracy    0.750\n",
      "| epoch   8 |    14/   17 batches | accuracy    0.688\n",
      "| epoch   8 |    15/   17 batches | accuracy    0.812\n",
      "| epoch   8 |    16/   17 batches | accuracy    0.857\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.10s | valid accuracy    0.719 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |     1/   17 batches | accuracy    0.781\n",
      "| epoch   9 |     2/   17 batches | accuracy    0.750\n",
      "| epoch   9 |     3/   17 batches | accuracy    0.875\n",
      "| epoch   9 |     4/   17 batches | accuracy    0.875\n",
      "| epoch   9 |     5/   17 batches | accuracy    0.812\n",
      "| epoch   9 |     6/   17 batches | accuracy    0.938\n",
      "| epoch   9 |     7/   17 batches | accuracy    0.812\n",
      "| epoch   9 |     8/   17 batches | accuracy    0.875\n",
      "| epoch   9 |     9/   17 batches | accuracy    0.750\n",
      "| epoch   9 |    10/   17 batches | accuracy    0.750\n",
      "| epoch   9 |    11/   17 batches | accuracy    0.812\n",
      "| epoch   9 |    12/   17 batches | accuracy    0.750\n",
      "| epoch   9 |    13/   17 batches | accuracy    0.812\n",
      "| epoch   9 |    14/   17 batches | accuracy    0.750\n",
      "| epoch   9 |    15/   17 batches | accuracy    0.688\n",
      "| epoch   9 |    16/   17 batches | accuracy    0.714\n",
      "Current Model ________\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.11s | valid accuracy    0.750 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |     1/   17 batches | accuracy    0.750\n",
      "| epoch  10 |     2/   17 batches | accuracy    0.938\n",
      "| epoch  10 |     3/   17 batches | accuracy    0.625\n",
      "| epoch  10 |     4/   17 batches | accuracy    0.875\n",
      "| epoch  10 |     5/   17 batches | accuracy    0.750\n",
      "| epoch  10 |     6/   17 batches | accuracy    0.938\n",
      "| epoch  10 |     7/   17 batches | accuracy    0.750\n",
      "| epoch  10 |     8/   17 batches | accuracy    0.750\n",
      "| epoch  10 |     9/   17 batches | accuracy    0.688\n",
      "| epoch  10 |    10/   17 batches | accuracy    0.875\n",
      "| epoch  10 |    11/   17 batches | accuracy    0.938\n",
      "| epoch  10 |    12/   17 batches | accuracy    0.938\n",
      "| epoch  10 |    13/   17 batches | accuracy    0.938\n",
      "| epoch  10 |    14/   17 batches | accuracy    0.688\n",
      "| epoch  10 |    15/   17 batches | accuracy    0.938\n",
      "| epoch  10 |    16/   17 batches | accuracy    0.857\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.11s | valid accuracy    0.750 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val = 0\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_loader)\n",
    "    accu_val = evaluate(validation_loader)\n",
    "    if accu_val > best_val:\n",
    "        print(\"Current Model ________\")\n",
    "        best_val = accu_val\n",
    "        model = model.to(\"cpu\")\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.750\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_loader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "continent = {0: \"North America\", 1: \"South America\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a South America artwork title\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"Fontamara\"\n",
    "\n",
    "print(\"This is a %s artwork title\"%continent[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': accu_val, 'embedding': model.embedding}, f='title_to_continent_torchtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, f='continent_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
