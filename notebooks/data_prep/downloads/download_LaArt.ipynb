{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import requests\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importing the Data from the National Gallery of Art (NGA)\n",
    "This NB reflects Step 2 of the LaArt Pipeline. First I import the metadata for the latinamerican portion of the art, which is a CSV file produced in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the metadata for La Art (this is a result of a MySql Database query script) with minor modifications\n",
    "la_image_metadata = pd.read_csv('../../../data_samples/LaArt/latinamerican_art.csv')\n",
    "shape_initial = la_image_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unneccessary rows (1 removed)\n",
    "la_image_metadata = la_image_metadata.where(la_image_metadata.title.apply(pd.notna)).dropna(how='all')\n",
    "la_image_metadata = la_image_metadata.where(la_image_metadata.forwarddisplayname.apply(pd.notna)).dropna(how='all')\n",
    "la_image_metadata = la_image_metadata.where(la_image_metadata.objectid.apply(pd.notna)).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(626, 44)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_image_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding expected file name (limiting title to 100 characters and concatenating it with forwardisplayname and objectid to create UUID filepath)\n",
    "la_image_metadata['file_name'] = la_image_metadata['title'].apply(lambda x: x.replace(' ','_').replace('/', '&')).apply(lambda x: x[:100]) + '_' + la_image_metadata['forwarddisplayname'].apply(lambda x: x.replace(' ', '_').replace('/', '&')) + '_' + la_image_metadata['objectid'].apply(lambda x: str(int(x)) + '.jpg')\n",
    "#adding the expected root directory of the image files\n",
    "la_image_directory = '../../../latinamerican-2-imagefolder-split/'\n",
    "la_image_metadata['directory'] = [la_image_directory] * len(la_image_metadata)\n",
    "#subfolder split (train 70% /test 30%) need to be identified randomly\n",
    "train_data, test_data = train_test_split(la_image_metadata, test_size=0.3)\n",
    "train_data['subfolder'] = ['train'] * len(train_data)\n",
    "test_data['subfolder'] = ['test'] * len(test_data)\n",
    "#adding new split (subfolder) column to la_image_metadata\n",
    "la_image_metadata = pd.concat([train_data, test_data]).reset_index(drop=True)\n",
    "# adding expected filepath (directory + filename)\n",
    "la_image_metadata['image_fp'] = la_image_metadata.directory + la_image_metadata.subfolder + '/' + la_image_metadata.file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the change in shape for input in M.L algs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape starting:  (626, 44)\n",
      "Shape after edit 1:  (626, 44)\n"
     ]
    }
   ],
   "source": [
    "#To verify data shape during process\n",
    "shape_change_1 = la_image_metadata.shape\n",
    "print('Shape starting: ', shape_initial)\n",
    "print('Shape after edit 1: ', shape_change_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iiifurl', 'iiifthumburl', 'title', 'displayDate_created', 'roletype',\n",
       "       'role', 'forwarddisplayname', 'birthyear', 'deathyear', 'ulanid',\n",
       "       'artistofngaobject', 'nationality', 'constituenttype',\n",
       "       'beginyear_artistAssigned', 'endyear_artistAssigned',\n",
       "       'country_artistAssigned', 'zipcode_artistAssigned', 'medium',\n",
       "       'dimensions', 'inscription', 'markings', 'attribution',\n",
       "       'visualBrowserClassification', 'parentID', 'isVirtual', 'portfolio',\n",
       "       'series', 'volume', 'watermarks', 'uuid', 'viewtype', 'sequence',\n",
       "       'width', 'height', 'maxpixels', 'assistivetext', 'depictstmsobjectid',\n",
       "       'objectid', 'constituentid', 'expanded_url', 'file_name', 'directory',\n",
       "       'subfolder', 'image_fp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_image_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects the features relevant to run the download script\n",
    "la_image_fpaths = la_image_metadata.loc[:, ['objectid', 'directory','subfolder','file_name', 'image_fp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Downloading the images from the open source NGA Database API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the images would be downloaded if ran as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download starting... please wait :)\n"
     ]
    }
   ],
   "source": [
    "## for next code section in notebook, images will be downloaded\n",
    "## I assume no images are downloaded & image_fp/directory not created\n",
    "def download_image(url, path, name, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        with open(name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        shutil.move(name, path)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "# Define HTTP Headers\n",
    "ua_header = {\n",
    "    \"User-Agent\": \"Chrome/51.0.2704.103\",\n",
    "}\n",
    "\n",
    "# this block now uses the la_image_fpaths table\n",
    "print(\"Download starting... please wait :)\")\n",
    "## This block iterates over all the images\n",
    "for i in range(0, len(la_image_fpaths)):\n",
    "    # Define URL of an image\n",
    "    expanded_url = la_image_metadata.expanded_url[i]\n",
    "    # Define image file name, file path to place\n",
    "    file_name = la_image_fpaths.file_name[i]\n",
    "    fp = la_image_fpaths.image_fp[i]\n",
    "    # Download image\n",
    "    # timer delay (15 seconds)\n",
    "    time.sleep(15)\n",
    "    download_image(expanded_url, fp, file_name, ua_header)\n",
    "    \n",
    "print(\"Download finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Verifying File Names Correspond to the Dataset (Some Images Unable to be Downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking that the filepath / naming conventions I used are consistent\n",
    "#from os.path import exists\n",
    "file_exists = []\n",
    "for i in range(len(la_image_fpaths)):\n",
    "    file_exists.append(exists(la_image_fpaths.image_fp[i]))\n",
    "la_image_fpaths['file_downloaded'] = file_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file name needs to be added to validLa_image_fpaths to be used in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['objectid', 'directory', 'subfolder', 'file_name', 'image_fp',\n",
       "       'file_downloaded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_image_fpaths.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the files edites / created in this NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where data is saved and outputted. If the .py files are run subsequently using the .sh script then the data will be edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The la_image_fp data will be split into two datasets (present/missing). Some of the images in the dataset were not downloaded successfully and splitting the dataset allows for the model to be trained without causing file not found errors, and for troubleshooting the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentLa_image_fpaths = la_image_fpaths.where(la_image_fpaths.file_downloaded == True).dropna(how='all')\n",
    "missingLa_image_fpaths = la_image_fpaths.where(la_image_fpaths.file_downloaded == False).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Created: ../../../data_samples/LaArt/presentLa_image_fpaths.csv\n",
      "CSV Created: ../../../data_samples/LaArt/missingLa_image_fpaths.csv\n"
     ]
    }
   ],
   "source": [
    "#saving the image fp data for use with the model\n",
    "presentLa_image_fpaths.to_csv('../../../data_samples/LaArt/presentLa_image_fpaths.csv', index=False)\n",
    "missingLa_image_fpaths.to_csv('../../../data_samples/LaArt/missingLa_image_fpaths.csv', index=False)\n",
    "print('CSV Created: ../../../data_samples/LaArt/presentLa_image_fpaths.csv')\n",
    "print('CSV Created: ../../../data_samples/LaArt/missingLa_image_fpaths.csv')\n",
    "la_image_metadata.to_csv('../../../data_samples/LaArt/latinamerican_art.csv', index=False)\n",
    "print('CSV Edited: ../../../data_samples/LaArt/latinamerican_art.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The amount of images downloaded is 0.7827476038338658 percent. Which means 489.99999999999994 is amount downloaded, out of 626 in latinamerican_art.csv'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_exists = la_image_fpaths.file_downloaded.sum()/len(file_exists)\n",
    "total = la_image_fpaths.shape[0]\n",
    "whole_num_exists = perc_exists * total\n",
    "text = 'The amount of images downloaded is {} percent. Which means {} is amount downloaded, out of {} in latinamerican_art.csv'\n",
    "text.format(perc_exists, whole_num_exists, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"download_LaArt.py finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
