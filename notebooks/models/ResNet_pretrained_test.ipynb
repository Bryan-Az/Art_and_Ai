{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314de801-b30c-4a75-8987-ce297e038298",
   "metadata": {},
   "source": [
    "### Using Pre-Trained ResNet Classification Model for Initial Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3f5aad-7448-40cc-b3d5-c385ec12efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models import resnet50, ResNet50_Weights\n",
    "#from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94b2a2-46bb-4d05-9017-f705e59cd7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Creating the Model\n",
    "#weights = ResNet50_Weights.DEFAULT\n",
    "#model = resnet50(weights=weights)\n",
    "#model.eval()\n",
    "##Step 2: Preprocessing Step for Inference (transforming the images)\n",
    "#preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db057ac-0b3b-46d9-bda2-55c75e0515f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 3: Apply previous step to all Images (To speed up the process, could use a dataloader to feed the images)\n",
    "#ResNet50_Accuracy = []\n",
    "#ResNet50_Prediction = []\n",
    "#for i in range(len(stored_latin_art)):\n",
    "#    img = Image.open(stored_latin_art.directory[i] + '/' + stored_latin_art.file_name[i])\n",
    "#    batch = preprocess(img).unsqueeze(0)\n",
    "#    prediction = model(batch).squeeze(0).softmax(0)\n",
    "#    # Step 4: Use the model and print the predicted category\n",
    "#    class_id = prediction.argmax().item()\n",
    "#    score = prediction[class_id].item()\n",
    "#    category_name = weights.meta[\"categories\"][class_id]\n",
    "#    ResNet50_Accuracy.append(100 * score)\n",
    "#    ResNet50_Prediction.append(category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38069b7-8f55-4c83-b3fc-0312cf5e2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = pd.DataFrame({'Image Accuracy - ResNet V2 (%)': ResNet50_Accuracy, 'Image Prediction - ResNet V2': ResNet50_Prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e884994-2be8-49ad-a3d9-8af60f5a6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = pd.concat([predictions, stored_latin_art.loc[:, ['title', 'forwarddisplayname']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5f636-4c42-45a3-a04f-bf69c6814362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.sort_values(by='Image Accuracy - ResNet V2 (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43825b2c-019b-4097-9ebb-1e720bb6ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions.to_csv('./data_samples/results/image_predictions_resnetv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37727c55-d898-478b-9162-0b7d8f0f6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = pd.read_csv('../data_samples/results/image_predictions_resnetv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f74722e-229e-4f02-8591-415d2b5e5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('../../data_samples/results/image_predictions_resnetv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce042aa-31cf-40ea-a221-7cab3bb5bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    328.000000\n",
       "mean      16.238882\n",
       "std       11.398615\n",
       "min        2.167588\n",
       "25%        7.772030\n",
       "50%       13.693587\n",
       "75%       19.781394\n",
       "max       60.189790\n",
       "Name: Image Accuracy - ResNet V2 (%), dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.loc[:, 'Image Accuracy - ResNet V2 (%)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69db2ebc-fa6f-4760-89e1-0aa6a83fbe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.693586736917496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = np.median(predictions.loc[:, 'Image Accuracy - ResNet V2 (%)'])\n",
    "median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d6a26-b4d4-4487-a014-891a374bc351",
   "metadata": {},
   "source": [
    "## Outcome\n",
    "Given the description above of the predictions using ResNet (A state of the art image classification algorithm) many of the objects which it predicted as belonging to the image have a very low score / accuracy. 50% of all the predictions have an accuracy in the range of ~8% to ~20%. 25% belong to the larger range of 20% to 60%, and the last 25% in the smaller and much worse range of ~2% to ~8%. This shows me that the predictions' distributions are shifted to the left and is tapered/skewed to the right-tail thus it is positively skewed and the mean>median, showing that larger scores are outliers.\n",
    "\n",
    "I think the reason the model is doing badly in its classification of an image / object, is because artwork contains many elements at times and is abstract so introducing noise to models which are trained on real-world photographs. To make better predictions, I will need to train my own model on the artwork, and extract labels from the dataset which give insight into the semantic meaning of the art itself. The labels will have to be general enough to have many pieces and training observations to make better predictions. Furthermore, I may need to lower the amount of classes used to maintain the size of the art data within each class. Furthermore, I may need to train the model on the entire NGA dataset, then perform classification on this smaller dataset to increase the size during the training phase.\n",
    "\n",
    "I also see value in trying to train the model with transfer learning on artwork, instead of simply relying on the pre-trained network which strictly uses images and not abstract forms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
